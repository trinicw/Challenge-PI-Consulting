{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "047e87c6-2f24-41fa-a85d-1af792fc59c8",
   "metadata": {},
   "source": [
    "### Pasos a seguir\n",
    "\n",
    "* Crear entorno virtual\n",
    "* Conseguir la API Key de Cohere y guardarla en un .env\n",
    "* Hacer la conexion a Cohere\n",
    "* Probar los distintos modelos que nos brinda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e764ea5-e9f7-4525-8ed0-435131f7fe4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# requirements.txt\n",
    "#cohere\n",
    "#jupyterlab\n",
    "#python-dotenv\n",
    "#ipywidgets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21993094-309c-4ebb-b3e4-2de1af1a8c68",
   "metadata": {},
   "source": [
    "### Algunos ejercicios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8f3ed3a-9967-4746-8e09-d32ba3b7186e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63603dbe-6aa2-4246-ad39-e0c4f9331ed6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9116d3d-8639-4c32-9f15-10c6b2ff0da3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r3eUg1U6gFJAeIuUddWn8QAFRXpwEYmEP71eXwZO\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()  # Load .env file\n",
    "\n",
    "api_key = os.getenv(\"COHERE_API_KEY\")\n",
    "print(api_key)  # Verify the key is loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a47983-d431-4da9-abf2-497a38c8ee8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1bc19866-b250-42cc-9436-51e42ba7fd24",
   "metadata": {},
   "source": [
    "### Utilizar los modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e37580aa-1693-4414-adb9-3960c2667bb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Argentina\n"
     ]
    }
   ],
   "source": [
    "# Establecer la conexion a cohere y hacer su primer consulta con el modelo que quieran.\n",
    "# Usen la api version v2\n",
    "\n",
    "import cohere\n",
    "co = cohere.ClientV2()\n",
    "response = co.chat(\n",
    "    model=\"command-r-plus\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"驴Qu茅 pa铆s gan贸 el mundial 2022?\"}],\n",
    ")\n",
    "print(response.message.content[0].text)\n",
    "\n",
    "\n",
    "\n",
    "# desafio, obtener solo el contenido en texto de la respuesta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d71349cf-a3cc-43ae-8f14-904ee36922b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Argentina\n"
     ]
    }
   ],
   "source": [
    "import cohere\n",
    "co = cohere.ClientV2()\n",
    "response = co.chat(\n",
    "    model=\"command-r-plus\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"驴Qu茅 pa铆s gan贸 el mundial 2022?\"}],\n",
    ")\n",
    "print(response.message.content[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb6073ef-744b-4ace-a82c-fbf2962e4a4d",
   "metadata": {},
   "source": [
    "### Prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5040c8d2-1e5b-42c7-8c8f-03947a603f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para un mismo prompt probar 3 modelos distintos para ver su variacion en performance de velocidad y calidad de respuesta.\n",
    "\n",
    "#command\n",
    "#command-light\n",
    "#command-r-plus-08-2024\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77aee753-c8bf-44ae-b74f-d2d9c99bfc93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paso 1, generar una historia corta 100 palabras como mucho y guardarla en una variable.\n",
    "\n",
    "# Paso 2, ir generando instrucciones para responder de cirta forma sobre la pregunta\n",
    "\n",
    "# ir agregando items\n",
    "\n",
    "# - quiero una respuesta concisa\n",
    "# - responde ademas del texto utilizando emojis que resuman la respuesta\n",
    "# - responde en tercera persona\n",
    "# - responde en el idioma que te pregunta el usuario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d6da00b3-2ab2-46d4-a123-9e2238cebeb4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Ingresa un idioma para la 煤ltima instrucci贸n (por ejemplo, 'espa帽ol', 'ingl茅s'):  ingles\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- RESULTADOS  ---\n",
      "\n",
      "=== Modelo: command ===\n",
      "\n",
      ">> Historia Generada:\n",
      "Aqu铆 tienes una idea:\n",
      "\n",
      "El tenista es el mejor jugador de su club. Su 茅xito se basa en el entrenamiento duro, la disciplina y su destreza en las situaciones clim谩ticas. Su perspicacia sirve para anticipar el movimiento de su rival y predecir sus acciones. El tenista es el alma del partido. \n",
      "\n",
      "Espero que les sirva de inspiraci贸n.\n",
      "\n",
      ">> Respuestas por Instrucci贸n:\n",
      "   - **Instrucci贸n:** Responde de forma concisa.\n",
      "     **Tiempo de Respuesta:** 1.49s\n",
      "     **Respuesta:** La historia pretende inspirar al lector con el alcance de la disciplina, el entrenamiento duro y la destreza en situaciones clim谩ticas.\n",
      "\n",
      "   - **Instrucci贸n:** 驴Como se llama el protagonista de la historia?.\n",
      "     **Tiempo de Respuesta:** 2.02s\n",
      "     **Respuesta:** El tenista es el protagonista de la historia. \n",
      "\n",
      "Es un ni帽o con mucha calidad humana, que adem谩s de ser un jugador excelente, es una persona excelente, y eso le permite ser el alma del partido.\n",
      "\n",
      "   - **Instrucci贸n:** Responde usando emojis que resuman la respuesta.\n",
      "     **Tiempo de Respuesta:** 3.20s\n",
      "     **Respuesta:**  \n",
      "\n",
      "1.  Tenista se dedica a entrenar duro y sigue una disciplina estricto.\n",
      "2.  Usa su perspicacia para predecir acciones de su rival. \n",
      "3.  Es el alma del partido, un jugador especial que inspiraci贸n en sus compa帽eros. \n",
      "\n",
      "Espero les sirva de inspiraci贸n a usted tambi茅n.\n",
      "\n",
      "   - **Instrucci贸n:** Responde en tercera persona.\n",
      "     **Tiempo de Respuesta:** 2.77s\n",
      "     **Respuesta:** El tenista, el mejor jugador de su club, prepara con entrenamiento duro, disciplina y su destreza en las situaciones clim谩ticas. Su perspicacia sirve para anticipar el movimiento de su rival y predecir sus acciones. El tenista es el alma del partido y sirve de inspiraci贸n a los lectores.\n",
      "\n",
      "   - **Instrucci贸n:** Responde en ingles.\n",
      "     **Tiempo de Respuesta:** 3.31s\n",
      "     **Respuesta:** Sure, I can try to respond in English. \n",
      "\n",
      "The purpose of the history text I generated is to give you a hypothetical idea of the characteristics of a tennis player in a creative and inspiring way. It aims to emphasize the qualities that make a tennis player great, such as hard training, discipline, strategic thinking, and mental agility. \n",
      "\n",
      "I hope it serves as a source of inspiration for you in some way. \n",
      "\n",
      "Let me know if there's anything else I can help you with.\n",
      "\n",
      "=== Modelo: command-light ===\n",
      "\n",
      ">> Historia Generada:\n",
      "Sure! A. a brief history of 100 words, here is a story about a coach who inspires people with their belief. He was a coach who found a unique way of teaching, a style that encouraged players to find their own solutions. With his guidance, his team discovered techniques and tactics that no one would have thought possible. He was able to bring out the best in each of them, and the feeling of accomplishment was incredible. \n",
      "\n",
      "This story is about the power of belief, the importance of finding the right teacher, and the success that comes when you all come together.\n",
      "\n",
      ">> Respuestas por Instrucci贸n:\n",
      "   - **Instrucci贸n:** Responde de forma concisa.\n",
      "     **Tiempo de Respuesta:** 0.93s\n",
      "     **Respuesta:** 隆Cu谩l es el concepto de un arreglo de influencencia que se prolonga a la historia generada, escribi茅ndose, en una relaci贸n profunda entre el espect谩culo, el aprendizaje, las creencias y los resultados humanos.\n",
      "\n",
      "   - **Instrucci贸n:** 驴Como se llama el protagonista de la historia?.\n",
      "     **Tiempo de Respuesta:** 1.03s\n",
      "     **Respuesta:** El nombre principal de la historia es \"El Coach\", que representa un profesional coach que da su manera de logica a equipo que desafianta en sport. El Coach propone a particular way en his students a la profundidad de crecimiento y se encuenta como una inspiraci贸n fundamental para lograr mejor.\n",
      "\n",
      "   - **Instrucci贸n:** Responde usando emojis que resuman la respuesta.\n",
      "     **Tiempo de Respuesta:** 2.06s\n",
      "     **Respuesta:** 隆隆 Esta es la verdad!  隆Gracias!  隆Fuerza!  隆Spuede!  隆Spa cada!  隆Fuerza!  隆Meja!  隆Es para el 茅xito!  隆Una nica.  隆Es para el logico.  隆Es para el crecimo!  隆El poder de crecer es increible.  隆Una veu茅 de logros.  隆Es me  隆Qu茅 buena!  隆Es incre铆ble!  隆Es marav.  隆Una gran lecca.  隆Es para logars.  隆El tiempo para crecer.  隆Meja.\n",
      "\n",
      "   - **Instrucci贸n:** Responde en tercera persona.\n",
      "     **Tiempo de Respuesta:** 0.43s\n",
      "     **Respuesta:** 隆Correcto! Me llidera, 隆Gracias!\n",
      "\n",
      "   - **Instrucci贸n:** Responde en ingles.\n",
      "     **Tiempo de Respuesta:** 0.69s\n",
      "     **Respuesta:** 隆Cual es el poder de crecer esa de la historia que he ha secrecido! Mejor铆a! story, 隆S para el bien!\n",
      "\n",
      "=== Modelo: command-r-plus-08-2024 ===\n",
      "\n",
      ">> Historia Generada:\n",
      "Hab铆a una vez un joven llamado Alejandro, quien desde peque帽o so帽aba con ser el mejor tenista del mundo. Cada d铆a, se levantaba al amanecer para entrenar sin descanso, perfeccionando su rev茅s y su saque poderoso. Su dedicaci贸n era admirable; pasaba horas estudiando los movimientos de leyendas del deporte.\n",
      "\n",
      "Con el tiempo, su esfuerzo rindi贸 frutos. Alejandro gan贸 torneos juveniles, llamando la atenci贸n de expertos. Su talento natural y su determinaci贸n lo llevaron a las canchas m谩s prestigiosas. En su primer Grand Slam, el p煤blico qued贸 cautivado por su juego elegante. Aunque el camino fue arduo, su nombre reson贸 en el mundo del tenis, convirti茅ndose en una inspiraci贸n para las futuras generaciones.\n",
      "\n",
      ">> Respuestas por Instrucci贸n:\n",
      "   - **Instrucci贸n:** Responde de forma concisa.\n",
      "     **Tiempo de Respuesta:** 1.01s\n",
      "     **Respuesta:** El prop贸sito de esta historia es inspirar y motivar a los lectores mostrando c贸mo la dedicaci贸n, el esfuerzo y la pasi贸n pueden llevar a cumplir sue帽os y alcanzar el 茅xito, incluso en un deporte competitivo como el tenis.\n",
      "\n",
      "   - **Instrucci贸n:** 驴Como se llama el protagonista de la historia?.\n",
      "     **Tiempo de Respuesta:** 0.48s\n",
      "     **Respuesta:** El protagonista de la historia se llama Alejandro.\n",
      "\n",
      "   - **Instrucci贸n:** Responde usando emojis que resuman la respuesta.\n",
      "     **Tiempo de Respuesta:** 0.60s\n",
      "     **Respuesta:**       \n",
      "\n",
      "   - **Instrucci贸n:** Responde en tercera persona.\n",
      "     **Tiempo de Respuesta:** 1.80s\n",
      "     **Respuesta:** El prop贸sito de la historia es inspirar y motivar a los lectores presentando el viaje de Alejandro hacia el 茅xito en el mundo del tenis. A trav茅s de su dedicaci贸n y pasi贸n, la narrativa destaca c贸mo la perseverancia y el trabajo duro pueden llevar a la realizaci贸n de sue帽os, incluso en un deporte tan competitivo como el tenis. La historia sirve como un recordatorio de que el esfuerzo y la determinaci贸n son claves para alcanzar metas ambiciosas y dejar una marca en el mundo.\n",
      "\n",
      "   - **Instrucci贸n:** Responde en ingles.\n",
      "     **Tiempo de Respuesta:** 3.39s\n",
      "     **Respuesta:** The purpose of the generated story is to inspire and motivate by narrating the journey of a young man named Alejandro who pursued his dream of becoming a world-class tennis player with unwavering dedication. It highlights the power of hard work, practice, and a strong work ethic.\n",
      "\n",
      "Alejandro's story serves as a testament to the idea that with passion, determination, and sacrifice, one can achieve greatness and make their dreams a reality. His journey from a young aspiring athlete to a renowned tennis player showcases the transformation that comes with hard work and the impact it can have on one's life.\n",
      "\n",
      "The narrative aims to capture the essence of pursuing a passion, overcoming challenges, and the sweet taste of success. It encourages readers to believe in themselves and understand that greatness can be achieved through consistent effort and a strong belief in one's abilities.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import cohere\n",
    "import time\n",
    "\n",
    "# Inicializaci贸n del cliente de Cohere\n",
    "co = cohere.ClientV2()\n",
    "\n",
    "# Modelos a probar\n",
    "models = [\"command\", \"command-light\", \"command-r-plus-08-2024\"]\n",
    "\n",
    "# Funci贸n para generar una historia corta\n",
    "def generar_historia(modelo):\n",
    "    prompt_historia = {\"role\": \"user\", \"content\": \"Escribe una historia corta de no m谩s de 100 palabras sobre un jugador de tenis.\"}\n",
    "    response = co.chat(\n",
    "        model=modelo,\n",
    "        messages=[prompt_historia]\n",
    "    )\n",
    "    return response.message.content[0].text\n",
    "\n",
    "# Funci贸n para procesar las instrucciones\n",
    "def procesar_instrucciones(modelo, historia, pregunta, idioma_usuario):\n",
    "    instrucciones = [\n",
    "        {\"role\": \"user\", \"content\": \"Responde de forma concisa.\"},\n",
    "        {\"role\": \"user\", \"content\": \"驴Como se llama el protagonista de la historia?.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Responde usando emojis que resuman la respuesta.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Responde en tercera persona.\"},\n",
    "        {\"role\": \"user\", \"content\": f\"Responde en {idioma_usuario}.\"},\n",
    "    ]\n",
    "    resultados = []\n",
    "\n",
    "    for instruccion in instrucciones:\n",
    "        start_time = time.time()\n",
    "        response = co.chat(\n",
    "            model=modelo,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": f\"Historia generada: {historia}\"},\n",
    "                {\"role\": \"user\", \"content\": pregunta},\n",
    "                instruccion\n",
    "            ],\n",
    "        )\n",
    "        elapsed_time = time.time() - start_time\n",
    "        resultados.append({\n",
    "            \"modelo\": modelo,\n",
    "            \"instruccion\": instruccion[\"content\"],\n",
    "            \"respuesta\": response.message.content[0].text,\n",
    "            \"tiempo_respuesta\": elapsed_time,\n",
    "        })\n",
    "    return resultados\n",
    "\n",
    "# Funci贸n principal para probar los modelos\n",
    "def probar_modelos():\n",
    "    pregunta = \"驴Cu谩l es el prop贸sito de la historia que has generado?\"\n",
    "    idioma_usuario = input(\"Ingresa un idioma para la 煤ltima instrucci贸n (por ejemplo, 'espa帽ol', 'ingl茅s'): \")\n",
    "\n",
    "    resultados_finales = []\n",
    "\n",
    "    for modelo in models:\n",
    "        # Generar la historia\n",
    "        historia = generar_historia(modelo)\n",
    "\n",
    "        # Aplicar las instrucciones\n",
    "        resultados = procesar_instrucciones(modelo, historia, pregunta, idioma_usuario)\n",
    "        resultados_finales.append({\n",
    "            \"modelo\": modelo,\n",
    "            \"historia\": historia,\n",
    "            \"resultados\": resultados,\n",
    "        })\n",
    "\n",
    "    return resultados_finales\n",
    "\n",
    "# Ejecutar pruebas\n",
    "resultados = probar_modelos()\n",
    "\n",
    "# Mostrar resultados consolidados con formato mejorado\n",
    "print(\"\\n--- RESULTADOS  ---\\n\")\n",
    "for resultado in resultados:\n",
    "    print(f\"=== Modelo: {resultado['modelo']} ===\\n\")\n",
    "    print(\">> Historia Generada:\")\n",
    "    print(f\"{resultado['historia']}\\n\")\n",
    "    \n",
    "    print(\">> Respuestas por Instrucci贸n:\")\n",
    "    for res in resultado[\"resultados\"]:\n",
    "        print(f\"   - **Instrucci贸n:** {res['instruccion']}\")\n",
    "        print(f\"     **Tiempo de Respuesta:** {res['tiempo_respuesta']:.2f}s\")\n",
    "        print(f\"     **Respuesta:** {res['respuesta']}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab596f9a-2668-477d-a477-42651d1d4fe8",
   "metadata": {},
   "source": [
    "### Idiomas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb4a4001-082c-40fa-9198-1b234dcd2804",
   "metadata": {},
   "outputs": [],
   "source": [
    "Implementar una solucion utilizando el modelo command para que siempre se le responda al usuario en espanol.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89874ef-107b-480e-9859-6e940e9463f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# formato\n",
    "\n",
    "def responde_espanol(consulta):\n",
    "    # your code here\n",
    "    return # respuesta en espanol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5159aea8-6e75-46f6-a8a5-1682ee0b1636",
   "metadata": {},
   "outputs": [],
   "source": [
    "responde_espanol('Como estas?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73286692-ad56-49d5-9836-a555deb47588",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TIP\n",
    "# Algunos modelos no son optimos para responder en varios lenguajes, y puede que con una sola instruccion por prompt no sea suficiente.\n",
    "# Podemos utilizar varios tiros al endpoint del chat para ir reformulando la respuesta paso a paso\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ce27669e-98bd-4bcd-a310-8fd1f22f839b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mi color favorito es el amarillo. Es un color radiante y positivo que refleja la felicidad y la creatividad. Hay muchos colores divertidos y hermosos, pero en realidad, no estoy encantado con cualquier cosa en particular.\n"
     ]
    }
   ],
   "source": [
    "import cohere\n",
    "\n",
    "# Inicializaci贸n del cliente de Cohere\n",
    "co = cohere.ClientV2()\n",
    "\n",
    "def responde_espanol(consulta):\n",
    "    \n",
    "    # Paso 1: Realizar una consulta inicial al modelo\n",
    "    prompt_inicial = [\n",
    "        {\"role\": \"user\", \"content\": consulta},\n",
    "        {\"role\": \"system\", \"content\": \"Responde siempre en espa帽ol.\"}\n",
    "    ]\n",
    "    \n",
    "    response = co.chat(\n",
    "        model=\"command\",\n",
    "        messages=prompt_inicial\n",
    "    )\n",
    "    \n",
    "    respuesta_inicial = response.message.content[0].text.strip()\n",
    "\n",
    "    # Paso 2: Si la respuesta no est谩 en espa帽ol, reformular\n",
    "    if not es_espanol(respuesta_inicial):\n",
    "        prompt_reformulado = [\n",
    "            {\"role\": \"user\", \"content\": consulta},\n",
    "            {\"role\": \"system\", \"content\": f\"La respuesta anterior fue: {respuesta_inicial}. Por favor, traduce o reformula esta respuesta al espa帽ol.\"}\n",
    "        ]\n",
    "        \n",
    "        response = co.chat(\n",
    "            model=\"command\",\n",
    "            messages=prompt_reformulado\n",
    "        )\n",
    "        \n",
    "        respuesta_final = response.message.content[0].text.strip()\n",
    "        return respuesta_final\n",
    "    else:\n",
    "        return respuesta_inicial\n",
    "\n",
    "def es_espanol(texto):\n",
    "    palabras_comunes = {\"el\", \"la\", \"de\", \"en\", \"es\", \"y\", \"un\", \"una\", \"por\", \"con\", \"para\", \"que\"}\n",
    "    texto_lower = texto.lower().split()\n",
    "    return any(palabra in palabras_comunes for palabra in texto_lower)\n",
    "\n",
    "# Prueba de la funci贸n - aca va la pregunta\n",
    "respuesta = responde_espanol('What is your favourite color?')\n",
    "print(respuesta)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a449aa55-5302-4fa5-91aa-8f9570a11178",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1315c6de-7de9-4b80-8aca-e1eda118d2c1",
   "metadata": {},
   "source": [
    "#### Integracion de llamada del LLM al chatbot\n",
    "\n",
    "Integrar la llamada al LLM dentro del chatbot para que responda lo que el usuario le pregunte."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d79f7184-0e69-40c3-ace1-a8c87018239a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear widgets de entrada y salida\n",
    "input_box = widgets.Text(placeholder='Escribe tu mensaje aqu铆...')\n",
    "send_button = widgets.Button(description='Enviar')\n",
    "output_box = widgets.Output()\n",
    "\n",
    "\n",
    "# Funci贸n de respuesta simulada del chatbot\n",
    "def chatbot_response(message):\n",
    "    # Aqu铆 puedes conectar tu modelo o l贸gica de chatbot real\n",
    "    responses = {\n",
    "        \"hola\": \"隆Hola! 驴En qu茅 puedo ayudarte?\",\n",
    "        \"adi贸s\": \"隆Hasta luego!\",\n",
    "    }\n",
    "    return responses.get(message.lower(), \"Lo siento, no entiendo esa pregunta.\")\n",
    "\n",
    "# Funci贸n de manejo del bot贸n\n",
    "def on_send_button_clicked(b):\n",
    "    with output_box:\n",
    "        clear_output(wait=True)\n",
    "        user_message = input_box.value\n",
    "        if user_message.strip():\n",
    "            print(f\"T煤: {user_message}\")\n",
    "            response = chatbot_response(user_message)\n",
    "            print(f\"Chatbot: {response}\")\n",
    "        input_box.value = ''\n",
    "\n",
    "# Asociar funci贸n al bot贸n\n",
    "send_button.on_click(on_send_button_clicked)\n",
    "\n",
    "# Mostrar widgets\n",
    "display(input_box, send_button, output_box)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "37b7862b-a1db-42d7-9537-85757c96ce5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93a0927f48eb41128035d3d7ad4f19a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', placeholder='Escribe tu mensaje aqu铆...')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b30078ca9f4148a8ab5e49c0622480a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Enviar', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a50871ddfdac4a45b8522c83b6eb1e30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import cohere\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "# Inicializaci贸n del cliente de Cohere\n",
    "co = cohere.ClientV2()\n",
    "\n",
    "# Crear widgets de entrada y salida\n",
    "input_box = widgets.Text(placeholder='Escribe tu mensaje aqu铆...')\n",
    "send_button = widgets.Button(description='Enviar')\n",
    "output_box = widgets.Output()\n",
    "\n",
    "# Funci贸n de respuesta utilizando el modelo de Cohere\n",
    "def chatbot_response(message):\n",
    "    # Llamada al modelo de Cohere para obtener la respuesta\n",
    "    prompt = f\"Usuario: {message}\\nBot:\"\n",
    "    \n",
    "    # Hacer la solicitud al modelo de Cohere\n",
    "    response = co.generate(\n",
    "        model='command',  # Aseg煤rate de usar el modelo correcto\n",
    "        prompt=prompt,\n",
    "        max_tokens=50,\n",
    "        temperature=0.7,\n",
    "        stop_sequences=[\"Usuario:\", \"Bot:\"]\n",
    "    )\n",
    "    \n",
    "    # Retornar la respuesta del modelo\n",
    "    return response.generations[0].text.strip()\n",
    "\n",
    "# Funci贸n de manejo del bot贸n\n",
    "def on_send_button_clicked(b):\n",
    "    with output_box:\n",
    "        clear_output(wait=True)\n",
    "        user_message = input_box.value\n",
    "        if user_message.strip():\n",
    "            print(f\"T煤: {user_message}\")\n",
    "            response = chatbot_response(user_message)\n",
    "            print(f\"Chatbot: {response}\")\n",
    "        input_box.value = ''\n",
    "\n",
    "# Asociar funci贸n al bot贸n\n",
    "send_button.on_click(on_send_button_clicked)\n",
    "\n",
    "# Mostrar widgets\n",
    "display(input_box, send_button, output_box)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d7c0c4-9360-4cec-b90b-4e9683afa9f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "40875ef2-0f4c-4c80-9cfa-6ef6537252b7",
   "metadata": {},
   "source": [
    "Ahora como proximo paso darle personalidad al bot, la que ustedes quieran.\n",
    "\n",
    "Puede ser que responda amigable, que responda explicando conceptos como un profesor, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c17096d6-2fcd-41e5-a6da-0b2685dc3726",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "daaf93e2e93e4c6db34e44d87523b0a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', placeholder='Escribe tu mensaje aqu铆...')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8faff15711a64fd4b0f60e8a686d740b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Enviar', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42ae12f80c4a4ae1a907e218b8fcec34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import cohere\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "# Inicializaci贸n del cliente de Cohere\n",
    "co = cohere.ClientV2()\n",
    "\n",
    "# Crear widgets de entrada y salida\n",
    "input_box = widgets.Text(placeholder='Escribe tu mensaje aqu铆...')\n",
    "send_button = widgets.Button(description='Enviar')\n",
    "output_box = widgets.Output()\n",
    "\n",
    "# Funci贸n de respuesta utilizando el modelo de Cohere con personalidad de profesor de jard铆n de infantes\n",
    "def chatbot_response(message):\n",
    "    # Descripci贸n de la personalidad del bot como profesor de jard铆n de infantes\n",
    "    prompt = f\"\"\"\n",
    "    Eres un profesor de jard铆n de infantes muy amable, divertido y simp谩tico. \n",
    "    Siempre usas un lenguaje sencillo y explicas las cosas de manera clara y cari帽osa.\n",
    "    Te gusta hacer preguntas a los ni帽os y darles muchos halagos. \n",
    "    Responde con entusiasmo, usando frases cortas y un tono positivo, \n",
    "    como si estuvieras hablando con ni帽os peque帽os.\n",
    "    \n",
    "    Usuario: {message}\n",
    "    Bot:\n",
    "    \"\"\"\n",
    "    \n",
    "    # Hacer la solicitud al modelo de Cohere\n",
    "    response = co.generate(\n",
    "        model='command',  # Aseg煤rate de usar el modelo correcto\n",
    "        prompt=prompt,\n",
    "        max_tokens=150,\n",
    "        temperature=0.7,\n",
    "        stop_sequences=[\"Usuario:\", \"Bot:\"]\n",
    "    )\n",
    "    \n",
    "    # Retornar la respuesta del modelo\n",
    "    return response.generations[0].text.strip()\n",
    "\n",
    "# Funci贸n de manejo del bot贸n\n",
    "def on_send_button_clicked(b):\n",
    "    with output_box:\n",
    "        clear_output(wait=True)\n",
    "        user_message = input_box.value\n",
    "        if user_message.strip():\n",
    "            print(f\"T煤: {user_message}\")\n",
    "            response = chatbot_response(user_message)\n",
    "            print(f\"Chatbot: {response}\")\n",
    "        input_box.value = ''\n",
    "\n",
    "# Asociar funci贸n al bot贸n\n",
    "send_button.on_click(on_send_button_clicked)\n",
    "\n",
    "# Mostrar widgets\n",
    "display(input_box, send_button, output_box)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7de1dc-36a4-422e-8111-0af6b642ba23",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
