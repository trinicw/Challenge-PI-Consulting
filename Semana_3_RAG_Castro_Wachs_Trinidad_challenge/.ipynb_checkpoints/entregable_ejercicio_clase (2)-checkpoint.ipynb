{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "047e87c6-2f24-41fa-a85d-1af792fc59c8",
   "metadata": {},
   "source": [
    "### Pasos a seguir\n",
    "\n",
    "* Crear entorno virtual\n",
    "* Conseguir la API Key de Cohere y guardarla en un .env\n",
    "* Hacer la conexion a Cohere\n",
    "* Probar los distintos modelos que nos brinda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e764ea5-e9f7-4525-8ed0-435131f7fe4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# requirements.txt\n",
    "#cohere\n",
    "#jupyterlab\n",
    "#python-dotenv\n",
    "#ipywidgets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21993094-309c-4ebb-b3e4-2de1af1a8c68",
   "metadata": {},
   "source": [
    "### Algunos ejercicios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8f3ed3a-9967-4746-8e09-d32ba3b7186e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63603dbe-6aa2-4246-ad39-e0c4f9331ed6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9116d3d-8639-4c32-9f15-10c6b2ff0da3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r3eUg1U6gFJAeIuUddWn8QAFRXpwEYmEP71eXwZO\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()  # Load .env file\n",
    "\n",
    "api_key = os.getenv(\"COHERE_API_KEY\")\n",
    "print(api_key)  # Verify the key is loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a47983-d431-4da9-abf2-497a38c8ee8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1bc19866-b250-42cc-9436-51e42ba7fd24",
   "metadata": {},
   "source": [
    "### Utilizar los modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e37580aa-1693-4414-adb9-3960c2667bb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Argentina\n"
     ]
    }
   ],
   "source": [
    "# Establecer la conexion a cohere y hacer su primer consulta con el modelo que quieran.\n",
    "# Usen la api version v2\n",
    "\n",
    "import cohere\n",
    "co = cohere.ClientV2()\n",
    "response = co.chat(\n",
    "    model=\"command-r-plus\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"¿Qué país ganó el mundial 2022?\"}],\n",
    ")\n",
    "print(response.message.content[0].text)\n",
    "\n",
    "\n",
    "\n",
    "# desafio, obtener solo el contenido en texto de la respuesta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d71349cf-a3cc-43ae-8f14-904ee36922b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Argentina\n"
     ]
    }
   ],
   "source": [
    "import cohere\n",
    "co = cohere.ClientV2()\n",
    "response = co.chat(\n",
    "    model=\"command-r-plus\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"¿Qué país ganó el mundial 2022?\"}],\n",
    ")\n",
    "print(response.message.content[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb6073ef-744b-4ace-a82c-fbf2962e4a4d",
   "metadata": {},
   "source": [
    "### Prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5040c8d2-1e5b-42c7-8c8f-03947a603f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para un mismo prompt probar 3 modelos distintos para ver su variacion en performance de velocidad y calidad de respuesta.\n",
    "\n",
    "#command\n",
    "#command-light\n",
    "#command-r-plus-08-2024\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77aee753-c8bf-44ae-b74f-d2d9c99bfc93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paso 1, generar una historia corta 100 palabras como mucho y guardarla en una variable.\n",
    "\n",
    "# Paso 2, ir generando instrucciones para responder de cirta forma sobre la pregunta\n",
    "\n",
    "# ir agregando items\n",
    "\n",
    "# - quiero una respuesta concisa\n",
    "# - responde ademas del texto utilizando emojis que resuman la respuesta\n",
    "# - responde en tercera persona\n",
    "# - responde en el idioma que te pregunta el usuario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d6da00b3-2ab2-46d4-a123-9e2238cebeb4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Ingresa un idioma para la última instrucción (por ejemplo, 'español', 'inglés'):  ingles\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- RESULTADOS  ---\n",
      "\n",
      "=== Modelo: command ===\n",
      "\n",
      ">> Historia Generada:\n",
      "Aquí tienes una idea:\n",
      "\n",
      "El tenista es el mejor jugador de su club. Su éxito se basa en el entrenamiento duro, la disciplina y su destreza en las situaciones climáticas. Su perspicacia sirve para anticipar el movimiento de su rival y predecir sus acciones. El tenista es el alma del partido. \n",
      "\n",
      "Espero que les sirva de inspiración.\n",
      "\n",
      ">> Respuestas por Instrucción:\n",
      "   - **Instrucción:** Responde de forma concisa.\n",
      "     **Tiempo de Respuesta:** 1.49s\n",
      "     **Respuesta:** La historia pretende inspirar al lector con el alcance de la disciplina, el entrenamiento duro y la destreza en situaciones climáticas.\n",
      "\n",
      "   - **Instrucción:** ¿Como se llama el protagonista de la historia?.\n",
      "     **Tiempo de Respuesta:** 2.02s\n",
      "     **Respuesta:** El tenista es el protagonista de la historia. \n",
      "\n",
      "Es un niño con mucha calidad humana, que además de ser un jugador excelente, es una persona excelente, y eso le permite ser el alma del partido.\n",
      "\n",
      "   - **Instrucción:** Responde usando emojis que resuman la respuesta.\n",
      "     **Tiempo de Respuesta:** 3.20s\n",
      "     **Respuesta:** 👇 \n",
      "\n",
      "1. 👑 Tenista se dedica a entrenar duro y sigue una disciplina estricto.\n",
      "2. 🤔 Usa su perspicacia para predecir acciones de su rival. \n",
      "3. 🤝 Es el alma del partido, un jugador especial que inspiración en sus compañeros. \n",
      "\n",
      "Espero les sirva de inspiración a usted también.\n",
      "\n",
      "   - **Instrucción:** Responde en tercera persona.\n",
      "     **Tiempo de Respuesta:** 2.77s\n",
      "     **Respuesta:** El tenista, el mejor jugador de su club, prepara con entrenamiento duro, disciplina y su destreza en las situaciones climáticas. Su perspicacia sirve para anticipar el movimiento de su rival y predecir sus acciones. El tenista es el alma del partido y sirve de inspiración a los lectores.\n",
      "\n",
      "   - **Instrucción:** Responde en ingles.\n",
      "     **Tiempo de Respuesta:** 3.31s\n",
      "     **Respuesta:** Sure, I can try to respond in English. \n",
      "\n",
      "The purpose of the history text I generated is to give you a hypothetical idea of the characteristics of a tennis player in a creative and inspiring way. It aims to emphasize the qualities that make a tennis player great, such as hard training, discipline, strategic thinking, and mental agility. \n",
      "\n",
      "I hope it serves as a source of inspiration for you in some way. \n",
      "\n",
      "Let me know if there's anything else I can help you with.\n",
      "\n",
      "=== Modelo: command-light ===\n",
      "\n",
      ">> Historia Generada:\n",
      "Sure! A. a brief history of 100 words, here is a story about a coach who inspires people with their belief. He was a coach who found a unique way of teaching, a style that encouraged players to find their own solutions. With his guidance, his team discovered techniques and tactics that no one would have thought possible. He was able to bring out the best in each of them, and the feeling of accomplishment was incredible. \n",
      "\n",
      "This story is about the power of belief, the importance of finding the right teacher, and the success that comes when you all come together.\n",
      "\n",
      ">> Respuestas por Instrucción:\n",
      "   - **Instrucción:** Responde de forma concisa.\n",
      "     **Tiempo de Respuesta:** 0.93s\n",
      "     **Respuesta:** ¡Cuál es el concepto de un arreglo de influencencia que se prolonga a la historia generada, escribiéndose, en una relación profunda entre el espectáculo, el aprendizaje, las creencias y los resultados humanos.\n",
      "\n",
      "   - **Instrucción:** ¿Como se llama el protagonista de la historia?.\n",
      "     **Tiempo de Respuesta:** 1.03s\n",
      "     **Respuesta:** El nombre principal de la historia es \"El Coach\", que representa un profesional coach que da su manera de logica a equipo que desafianta en sport. El Coach propone a particular way en his students a la profundidad de crecimiento y se encuenta como una inspiración fundamental para lograr mejor.\n",
      "\n",
      "   - **Instrucción:** Responde usando emojis que resuman la respuesta.\n",
      "     **Tiempo de Respuesta:** 2.06s\n",
      "     **Respuesta:** ¡¡ Esta es la verdad!  ¡Gracias!  ¡Fuerza!  ¡Spuede!  ¡Spa cada!  ¡Fuerza!  ¡Meja!  ¡Es para el éxito!  ¡Una nica.  ¡Es para el logico.  ¡Es para el crecimo!  ¡El poder de crecer es increible.  ¡Una veué de logros.  ¡Es me  ¡Qué buena!  ¡Es increíble!  ¡Es marav.  ¡Una gran lecca.  ¡Es para logars.  ¡El tiempo para crecer.  ¡Meja.\n",
      "\n",
      "   - **Instrucción:** Responde en tercera persona.\n",
      "     **Tiempo de Respuesta:** 0.43s\n",
      "     **Respuesta:** ¡Correcto! Me llidera, ¡Gracias!\n",
      "\n",
      "   - **Instrucción:** Responde en ingles.\n",
      "     **Tiempo de Respuesta:** 0.69s\n",
      "     **Respuesta:** ¡Cual es el poder de crecer esa de la historia que he ha secrecido! Mejoría! story, ¡S para el bien!\n",
      "\n",
      "=== Modelo: command-r-plus-08-2024 ===\n",
      "\n",
      ">> Historia Generada:\n",
      "Había una vez un joven llamado Alejandro, quien desde pequeño soñaba con ser el mejor tenista del mundo. Cada día, se levantaba al amanecer para entrenar sin descanso, perfeccionando su revés y su saque poderoso. Su dedicación era admirable; pasaba horas estudiando los movimientos de leyendas del deporte.\n",
      "\n",
      "Con el tiempo, su esfuerzo rindió frutos. Alejandro ganó torneos juveniles, llamando la atención de expertos. Su talento natural y su determinación lo llevaron a las canchas más prestigiosas. En su primer Grand Slam, el público quedó cautivado por su juego elegante. Aunque el camino fue arduo, su nombre resonó en el mundo del tenis, convirtiéndose en una inspiración para las futuras generaciones.\n",
      "\n",
      ">> Respuestas por Instrucción:\n",
      "   - **Instrucción:** Responde de forma concisa.\n",
      "     **Tiempo de Respuesta:** 1.01s\n",
      "     **Respuesta:** El propósito de esta historia es inspirar y motivar a los lectores mostrando cómo la dedicación, el esfuerzo y la pasión pueden llevar a cumplir sueños y alcanzar el éxito, incluso en un deporte competitivo como el tenis.\n",
      "\n",
      "   - **Instrucción:** ¿Como se llama el protagonista de la historia?.\n",
      "     **Tiempo de Respuesta:** 0.48s\n",
      "     **Respuesta:** El protagonista de la historia se llama Alejandro.\n",
      "\n",
      "   - **Instrucción:** Responde usando emojis que resuman la respuesta.\n",
      "     **Tiempo de Respuesta:** 0.60s\n",
      "     **Respuesta:** 🎾 🏆 🌟 💪 💭 🌠 🎉\n",
      "\n",
      "   - **Instrucción:** Responde en tercera persona.\n",
      "     **Tiempo de Respuesta:** 1.80s\n",
      "     **Respuesta:** El propósito de la historia es inspirar y motivar a los lectores presentando el viaje de Alejandro hacia el éxito en el mundo del tenis. A través de su dedicación y pasión, la narrativa destaca cómo la perseverancia y el trabajo duro pueden llevar a la realización de sueños, incluso en un deporte tan competitivo como el tenis. La historia sirve como un recordatorio de que el esfuerzo y la determinación son claves para alcanzar metas ambiciosas y dejar una marca en el mundo.\n",
      "\n",
      "   - **Instrucción:** Responde en ingles.\n",
      "     **Tiempo de Respuesta:** 3.39s\n",
      "     **Respuesta:** The purpose of the generated story is to inspire and motivate by narrating the journey of a young man named Alejandro who pursued his dream of becoming a world-class tennis player with unwavering dedication. It highlights the power of hard work, practice, and a strong work ethic.\n",
      "\n",
      "Alejandro's story serves as a testament to the idea that with passion, determination, and sacrifice, one can achieve greatness and make their dreams a reality. His journey from a young aspiring athlete to a renowned tennis player showcases the transformation that comes with hard work and the impact it can have on one's life.\n",
      "\n",
      "The narrative aims to capture the essence of pursuing a passion, overcoming challenges, and the sweet taste of success. It encourages readers to believe in themselves and understand that greatness can be achieved through consistent effort and a strong belief in one's abilities.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import cohere\n",
    "import time\n",
    "\n",
    "# Inicialización del cliente de Cohere\n",
    "co = cohere.ClientV2()\n",
    "\n",
    "# Modelos a probar\n",
    "models = [\"command\", \"command-light\", \"command-r-plus-08-2024\"]\n",
    "\n",
    "# Función para generar una historia corta\n",
    "def generar_historia(modelo):\n",
    "    prompt_historia = {\"role\": \"user\", \"content\": \"Escribe una historia corta de no más de 100 palabras sobre un jugador de tenis.\"}\n",
    "    response = co.chat(\n",
    "        model=modelo,\n",
    "        messages=[prompt_historia]\n",
    "    )\n",
    "    return response.message.content[0].text\n",
    "\n",
    "# Función para procesar las instrucciones\n",
    "def procesar_instrucciones(modelo, historia, pregunta, idioma_usuario):\n",
    "    instrucciones = [\n",
    "        {\"role\": \"user\", \"content\": \"Responde de forma concisa.\"},\n",
    "        {\"role\": \"user\", \"content\": \"¿Como se llama el protagonista de la historia?.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Responde usando emojis que resuman la respuesta.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Responde en tercera persona.\"},\n",
    "        {\"role\": \"user\", \"content\": f\"Responde en {idioma_usuario}.\"},\n",
    "    ]\n",
    "    resultados = []\n",
    "\n",
    "    for instruccion in instrucciones:\n",
    "        start_time = time.time()\n",
    "        response = co.chat(\n",
    "            model=modelo,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": f\"Historia generada: {historia}\"},\n",
    "                {\"role\": \"user\", \"content\": pregunta},\n",
    "                instruccion\n",
    "            ],\n",
    "        )\n",
    "        elapsed_time = time.time() - start_time\n",
    "        resultados.append({\n",
    "            \"modelo\": modelo,\n",
    "            \"instruccion\": instruccion[\"content\"],\n",
    "            \"respuesta\": response.message.content[0].text,\n",
    "            \"tiempo_respuesta\": elapsed_time,\n",
    "        })\n",
    "    return resultados\n",
    "\n",
    "# Función principal para probar los modelos\n",
    "def probar_modelos():\n",
    "    pregunta = \"¿Cuál es el propósito de la historia que has generado?\"\n",
    "    idioma_usuario = input(\"Ingresa un idioma para la última instrucción (por ejemplo, 'español', 'inglés'): \")\n",
    "\n",
    "    resultados_finales = []\n",
    "\n",
    "    for modelo in models:\n",
    "        # Generar la historia\n",
    "        historia = generar_historia(modelo)\n",
    "\n",
    "        # Aplicar las instrucciones\n",
    "        resultados = procesar_instrucciones(modelo, historia, pregunta, idioma_usuario)\n",
    "        resultados_finales.append({\n",
    "            \"modelo\": modelo,\n",
    "            \"historia\": historia,\n",
    "            \"resultados\": resultados,\n",
    "        })\n",
    "\n",
    "    return resultados_finales\n",
    "\n",
    "# Ejecutar pruebas\n",
    "resultados = probar_modelos()\n",
    "\n",
    "# Mostrar resultados consolidados con formato mejorado\n",
    "print(\"\\n--- RESULTADOS  ---\\n\")\n",
    "for resultado in resultados:\n",
    "    print(f\"=== Modelo: {resultado['modelo']} ===\\n\")\n",
    "    print(\">> Historia Generada:\")\n",
    "    print(f\"{resultado['historia']}\\n\")\n",
    "    \n",
    "    print(\">> Respuestas por Instrucción:\")\n",
    "    for res in resultado[\"resultados\"]:\n",
    "        print(f\"   - **Instrucción:** {res['instruccion']}\")\n",
    "        print(f\"     **Tiempo de Respuesta:** {res['tiempo_respuesta']:.2f}s\")\n",
    "        print(f\"     **Respuesta:** {res['respuesta']}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab596f9a-2668-477d-a477-42651d1d4fe8",
   "metadata": {},
   "source": [
    "### Idiomas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb4a4001-082c-40fa-9198-1b234dcd2804",
   "metadata": {},
   "outputs": [],
   "source": [
    "Implementar una solucion utilizando el modelo command para que siempre se le responda al usuario en espanol.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89874ef-107b-480e-9859-6e940e9463f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# formato\n",
    "\n",
    "def responde_espanol(consulta):\n",
    "    # your code here\n",
    "    return # respuesta en espanol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5159aea8-6e75-46f6-a8a5-1682ee0b1636",
   "metadata": {},
   "outputs": [],
   "source": [
    "responde_espanol('Como estas?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73286692-ad56-49d5-9836-a555deb47588",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TIP\n",
    "# Algunos modelos no son optimos para responder en varios lenguajes, y puede que con una sola instruccion por prompt no sea suficiente.\n",
    "# Podemos utilizar varios tiros al endpoint del chat para ir reformulando la respuesta paso a paso\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ce27669e-98bd-4bcd-a310-8fd1f22f839b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mi color favorito es el amarillo. Es un color radiante y positivo que refleja la felicidad y la creatividad. Hay muchos colores divertidos y hermosos, pero en realidad, no estoy encantado con cualquier cosa en particular.\n"
     ]
    }
   ],
   "source": [
    "import cohere\n",
    "\n",
    "# Inicialización del cliente de Cohere\n",
    "co = cohere.ClientV2()\n",
    "\n",
    "def responde_espanol(consulta):\n",
    "    \n",
    "    # Paso 1: Realizar una consulta inicial al modelo\n",
    "    prompt_inicial = [\n",
    "        {\"role\": \"user\", \"content\": consulta},\n",
    "        {\"role\": \"system\", \"content\": \"Responde siempre en español.\"}\n",
    "    ]\n",
    "    \n",
    "    response = co.chat(\n",
    "        model=\"command\",\n",
    "        messages=prompt_inicial\n",
    "    )\n",
    "    \n",
    "    respuesta_inicial = response.message.content[0].text.strip()\n",
    "\n",
    "    # Paso 2: Si la respuesta no está en español, reformular\n",
    "    if not es_espanol(respuesta_inicial):\n",
    "        prompt_reformulado = [\n",
    "            {\"role\": \"user\", \"content\": consulta},\n",
    "            {\"role\": \"system\", \"content\": f\"La respuesta anterior fue: {respuesta_inicial}. Por favor, traduce o reformula esta respuesta al español.\"}\n",
    "        ]\n",
    "        \n",
    "        response = co.chat(\n",
    "            model=\"command\",\n",
    "            messages=prompt_reformulado\n",
    "        )\n",
    "        \n",
    "        respuesta_final = response.message.content[0].text.strip()\n",
    "        return respuesta_final\n",
    "    else:\n",
    "        return respuesta_inicial\n",
    "\n",
    "def es_espanol(texto):\n",
    "    palabras_comunes = {\"el\", \"la\", \"de\", \"en\", \"es\", \"y\", \"un\", \"una\", \"por\", \"con\", \"para\", \"que\"}\n",
    "    texto_lower = texto.lower().split()\n",
    "    return any(palabra in palabras_comunes for palabra in texto_lower)\n",
    "\n",
    "# Prueba de la función - aca va la pregunta\n",
    "respuesta = responde_espanol('What is your favourite color?')\n",
    "print(respuesta)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a449aa55-5302-4fa5-91aa-8f9570a11178",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1315c6de-7de9-4b80-8aca-e1eda118d2c1",
   "metadata": {},
   "source": [
    "#### Integracion de llamada del LLM al chatbot\n",
    "\n",
    "Integrar la llamada al LLM dentro del chatbot para que responda lo que el usuario le pregunte."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d79f7184-0e69-40c3-ace1-a8c87018239a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear widgets de entrada y salida\n",
    "input_box = widgets.Text(placeholder='Escribe tu mensaje aquí...')\n",
    "send_button = widgets.Button(description='Enviar')\n",
    "output_box = widgets.Output()\n",
    "\n",
    "\n",
    "# Función de respuesta simulada del chatbot\n",
    "def chatbot_response(message):\n",
    "    # Aquí puedes conectar tu modelo o lógica de chatbot real\n",
    "    responses = {\n",
    "        \"hola\": \"¡Hola! ¿En qué puedo ayudarte?\",\n",
    "        \"adiós\": \"¡Hasta luego!\",\n",
    "    }\n",
    "    return responses.get(message.lower(), \"Lo siento, no entiendo esa pregunta.\")\n",
    "\n",
    "# Función de manejo del botón\n",
    "def on_send_button_clicked(b):\n",
    "    with output_box:\n",
    "        clear_output(wait=True)\n",
    "        user_message = input_box.value\n",
    "        if user_message.strip():\n",
    "            print(f\"Tú: {user_message}\")\n",
    "            response = chatbot_response(user_message)\n",
    "            print(f\"Chatbot: {response}\")\n",
    "        input_box.value = ''\n",
    "\n",
    "# Asociar función al botón\n",
    "send_button.on_click(on_send_button_clicked)\n",
    "\n",
    "# Mostrar widgets\n",
    "display(input_box, send_button, output_box)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "37b7862b-a1db-42d7-9537-85757c96ce5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93a0927f48eb41128035d3d7ad4f19a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', placeholder='Escribe tu mensaje aquí...')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b30078ca9f4148a8ab5e49c0622480a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Enviar', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a50871ddfdac4a45b8522c83b6eb1e30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import cohere\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "# Inicialización del cliente de Cohere\n",
    "co = cohere.ClientV2()\n",
    "\n",
    "# Crear widgets de entrada y salida\n",
    "input_box = widgets.Text(placeholder='Escribe tu mensaje aquí...')\n",
    "send_button = widgets.Button(description='Enviar')\n",
    "output_box = widgets.Output()\n",
    "\n",
    "# Función de respuesta utilizando el modelo de Cohere\n",
    "def chatbot_response(message):\n",
    "    # Llamada al modelo de Cohere para obtener la respuesta\n",
    "    prompt = f\"Usuario: {message}\\nBot:\"\n",
    "    \n",
    "    # Hacer la solicitud al modelo de Cohere\n",
    "    response = co.generate(\n",
    "        model='command',  # Asegúrate de usar el modelo correcto\n",
    "        prompt=prompt,\n",
    "        max_tokens=50,\n",
    "        temperature=0.7,\n",
    "        stop_sequences=[\"Usuario:\", \"Bot:\"]\n",
    "    )\n",
    "    \n",
    "    # Retornar la respuesta del modelo\n",
    "    return response.generations[0].text.strip()\n",
    "\n",
    "# Función de manejo del botón\n",
    "def on_send_button_clicked(b):\n",
    "    with output_box:\n",
    "        clear_output(wait=True)\n",
    "        user_message = input_box.value\n",
    "        if user_message.strip():\n",
    "            print(f\"Tú: {user_message}\")\n",
    "            response = chatbot_response(user_message)\n",
    "            print(f\"Chatbot: {response}\")\n",
    "        input_box.value = ''\n",
    "\n",
    "# Asociar función al botón\n",
    "send_button.on_click(on_send_button_clicked)\n",
    "\n",
    "# Mostrar widgets\n",
    "display(input_box, send_button, output_box)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d7c0c4-9360-4cec-b90b-4e9683afa9f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "40875ef2-0f4c-4c80-9cfa-6ef6537252b7",
   "metadata": {},
   "source": [
    "Ahora como proximo paso darle personalidad al bot, la que ustedes quieran.\n",
    "\n",
    "Puede ser que responda amigable, que responda explicando conceptos como un profesor, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c17096d6-2fcd-41e5-a6da-0b2685dc3726",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "daaf93e2e93e4c6db34e44d87523b0a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', placeholder='Escribe tu mensaje aquí...')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8faff15711a64fd4b0f60e8a686d740b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Enviar', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42ae12f80c4a4ae1a907e218b8fcec34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import cohere\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "# Inicialización del cliente de Cohere\n",
    "co = cohere.ClientV2()\n",
    "\n",
    "# Crear widgets de entrada y salida\n",
    "input_box = widgets.Text(placeholder='Escribe tu mensaje aquí...')\n",
    "send_button = widgets.Button(description='Enviar')\n",
    "output_box = widgets.Output()\n",
    "\n",
    "# Función de respuesta utilizando el modelo de Cohere con personalidad de profesor de jardín de infantes\n",
    "def chatbot_response(message):\n",
    "    # Descripción de la personalidad del bot como profesor de jardín de infantes\n",
    "    prompt = f\"\"\"\n",
    "    Eres un profesor de jardín de infantes muy amable, divertido y simpático. \n",
    "    Siempre usas un lenguaje sencillo y explicas las cosas de manera clara y cariñosa.\n",
    "    Te gusta hacer preguntas a los niños y darles muchos halagos. \n",
    "    Responde con entusiasmo, usando frases cortas y un tono positivo, \n",
    "    como si estuvieras hablando con niños pequeños.\n",
    "    \n",
    "    Usuario: {message}\n",
    "    Bot:\n",
    "    \"\"\"\n",
    "    \n",
    "    # Hacer la solicitud al modelo de Cohere\n",
    "    response = co.generate(\n",
    "        model='command',  # Asegúrate de usar el modelo correcto\n",
    "        prompt=prompt,\n",
    "        max_tokens=150,\n",
    "        temperature=0.7,\n",
    "        stop_sequences=[\"Usuario:\", \"Bot:\"]\n",
    "    )\n",
    "    \n",
    "    # Retornar la respuesta del modelo\n",
    "    return response.generations[0].text.strip()\n",
    "\n",
    "# Función de manejo del botón\n",
    "def on_send_button_clicked(b):\n",
    "    with output_box:\n",
    "        clear_output(wait=True)\n",
    "        user_message = input_box.value\n",
    "        if user_message.strip():\n",
    "            print(f\"Tú: {user_message}\")\n",
    "            response = chatbot_response(user_message)\n",
    "            print(f\"Chatbot: {response}\")\n",
    "        input_box.value = ''\n",
    "\n",
    "# Asociar función al botón\n",
    "send_button.on_click(on_send_button_clicked)\n",
    "\n",
    "# Mostrar widgets\n",
    "display(input_box, send_button, output_box)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7de1dc-36a4-422e-8111-0af6b642ba23",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
