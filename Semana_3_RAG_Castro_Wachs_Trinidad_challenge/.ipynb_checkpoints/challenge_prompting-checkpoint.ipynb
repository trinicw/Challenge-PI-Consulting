{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92de8ca4-7181-45f5-9980-b723d2566f5e",
   "metadata": {},
   "source": [
    "# Challenge Prompting\n",
    "\n",
    "Resolver los siguientes ejercicios dejando el codigo con su ejecucion.\n",
    "\n",
    "Importar las librerias necesarias y **correr las celdas para visualizar el resultado en cada ejercicio**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65bbb09-0f5a-4e97-9a06-2361c5cdd1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## bloque importacion de librerias\n",
    "\n",
    "import json\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e004e5b7-b704-4592-b8b4-b01b8d6687cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## bloque variables de entorno\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()  # Load .env file\n",
    "\n",
    "api_key = os.getenv(\"COHERE_API_KEY\")\n",
    "print(api_key)  # Verify the key is loaded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd6745ff-cd45-4231-b3d6-518954a9ffca",
   "metadata": {},
   "outputs": [],
   "source": [
    "## bloque conexion a Cohere\n",
    "\n",
    "co = cohere.ClientV2()\n",
    "# alternativa:\n",
    "# co = cohere.ClientV2(api_key)\n",
    "\n",
    "response = co.chat(\n",
    "    model=\"command-r-plus-08-2024\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"hello world!\"}],\n",
    ")\n",
    "\n",
    "print(response)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aacdb26-ce51-49cc-b37f-5aa45c09ff51",
   "metadata": {},
   "source": [
    "## Ejercicio 1\n",
    "\n",
    "Extraccion de entidades\n",
    "\n",
    "Utilizar el LLM para extraer las siguientes entidades del texto medico.\n",
    "\n",
    "- Paciente:\n",
    "    - Nombre\n",
    "    - Edad\n",
    "- Fecha de admisión\n",
    "- Síntomas\n",
    "- Diagnóstico\n",
    "- Tratamiento recomendado\n",
    "\n",
    "**Aclaracion:** \n",
    "\n",
    "La salida tiene que ser un **string con formato de tipo json**, el cual se convertira en un diccionario de Python.\n",
    "\n",
    "Si la linea de conversion en test da error el ejercicio no esta completo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750e43d7-b074-4973-9cd0-5a6fbe816084",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ejemplo \n",
    "\n",
    "# texto a analizar\n",
    "\"\"\"La paciente, María González, de 45 años, fue admitida en el Hospital Central el 5 de agosto de 2023 debido a síntomas de fatiga crónica y dolores musculares./\n",
    "Tras una serie de análisis, se diagnosticó fibromialgia. La doctora a cargo, Laura Ramírez, recomendó un tratamiento basado en fisioterapia y medicamentos analgésicos. /\n",
    "La próxima consulta está programada para el 15 de septiembre.\"\"\"\n",
    "\n",
    "\n",
    "# respuesta del LLM\n",
    "{\n",
    "  \"paciente\": {\n",
    "    \"nombre\": \"María González\",\n",
    "    \"edad\": 45\n",
    "  },\n",
    "  \"fecha_admision\": \"2023-08-05\",\n",
    "  \"sintomas\": [\n",
    "    \"fatiga crónica\",\n",
    "    \"dolores musculares\"\n",
    "  ],\n",
    "  \"diagnostico\": \"fibromialgia\",\n",
    "  \"tratamiento\": [\n",
    "    \"fisioterapia\",\n",
    "    \"medicamentos analgésicos\"\n",
    "  ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac8d0a6-db5c-4eec-9f71-89e60ceaf914",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "425cffab-9efd-4d80-bc64-6ef69ce233e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_to_analize = \"\"\"Sofía López, de 28 años, ingresó al Hospital Infantil el 3 de abril de 2023 debido a fiebre alta y tos persistente./\n",
    "Después de varias pruebas, se le diagnosticó neumonía. La pediatra responsable, Dra. Claudia Torres, indicó tratamiento con antibióticos y reposo./\n",
    "La próxima evaluación será el 10 de abril.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2ff6d292-d4cb-4484-811e-d0d641c66d1c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"Paciente\": {\n",
      "    \"Nombre\": \"Sofía López\",\n",
      "    \"Edad\": \"28 años\"\n",
      "  },\n",
      "  \"Fecha de admisión\": \"3 de abril de 2023\",\n",
      "  \"Síntomas\": \"Fiebre alta y tos persistente\",\n",
      "  \"Diagnóstico\": \"Neumonía\",\n",
      "  \"Tratamiento recomendado\": \"Antibióticos y reposo\"\n",
      "}\n",
      "{'Paciente': {'Nombre': 'Sofía López', 'Edad': '28 años'}, 'Fecha de admisión': '3 de abril de 2023', 'Síntomas': 'Fiebre alta y tos persistente', 'Diagnóstico': 'Neumonía', 'Tratamiento recomendado': 'Antibióticos y reposo'}\n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "\n",
    "import json\n",
    "import cohere\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Cargar las variables de entorno desde el archivo .env\n",
    "load_dotenv()\n",
    "\n",
    "# Obtener la clave de API desde la variable de entorno\n",
    "api_key = os.getenv(\"COHERE_API_KEY\")\n",
    "\n",
    "# Inicializa el cliente de Cohere usando la clave de API desde la variable de entorno\n",
    "co = cohere.ClientV2(api_key)\n",
    "\n",
    "text_to_analize = \"\"\"Sofía López, de 28 años, ingresó al Hospital Infantil el 3 de abril de 2023 debido a fiebre alta y tos persistente./\n",
    "Después de varias pruebas, se le diagnosticó neumonía. La pediatra responsable, Dra. Claudia Torres, indicó tratamiento con antibióticos y reposo./\n",
    "La próxima evaluación será el 10 de abril.\"\"\"\n",
    "\n",
    "# prompt con las instrucciones\n",
    "\n",
    "system_prompt = \"Lo unico que tenes que hacer es responder a las preguntas usando el contexto como base de informacion para armar la respuesta\"\n",
    "\n",
    "prompt = f\"\"\"\n",
    "            ###\n",
    "            Intrucciones:\n",
    "            1. extraer las siguientes entidades del texto medico. La salida (tu respuesta) tiene que ser un string con formato de tipo json\n",
    "                Paciente:\n",
    "                    Nombre\n",
    "                    Edad\n",
    "                Fecha de admisión\n",
    "                Síntomas\n",
    "                Diagnóstico\n",
    "                Tratamiento recomendado\n",
    "                \n",
    "            ###\n",
    "            Contexto:\n",
    "            {text_to_analize}\n",
    "            ###\n",
    "            \n",
    "            \"\"\"\n",
    "\n",
    "llm_response = co.chat(\n",
    "    model=\"command-r-plus-08-2024\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\":system_prompt},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(llm_response.message.content[0].text)\n",
    "\n",
    "# test\n",
    "# Acceder correctamente al texto JSON dentro del objeto `llm_response`\n",
    "json_text = llm_response.message.content[0].text\n",
    "\n",
    "# test\n",
    "final_result = json.loads(json_text)\n",
    "\n",
    "# Imprimir el resultado del diccionario\n",
    "print(final_result)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f6f0009-8a9c-49a3-b740-d73e0dbe765e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "final_result = json.loads(json_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097ee190-faca-46d8-9c11-0f8904bd1752",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df0e72e5-3bd5-4f26-860c-340e25e72f04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b37fbf25-6db4-432a-82c4-2e7edce27686",
   "metadata": {},
   "source": [
    "## Ejercicio 2\n",
    "\n",
    "Tenemos dos funciones en Python, una llamada *'add_contact'* y otra llamada *'get_information'*.\n",
    "\n",
    "**Utilizar algun LLM que permita funtion calling** y desarrollar un codigo secuencial automatico que consiga:\n",
    "\n",
    "Interpretar la consulta del usuario, identificar a que funcion llamar, luego llamarla (si es que aplica) y darle una respuesta final al usuario.  (usar function calling para esta solucion)\n",
    "\n",
    "La entrada a dicho codigo es la consulta del usuario, a continuacion algunos ejemplos:\n",
    "\n",
    "- \"Agrega a Juan Pérez con el número 555-1234 y el correo juanperez@mail.com.\"\n",
    "- \"Guarda a Lucía Gómez en mis contactos. Su teléfono es 555-5678 y su email es lucia.gomez@gmail.com.\"\n",
    "- \"Cual es el Email de Juan Pérez.?\"\n",
    "\n",
    "Salidas esperadas de dichos ejemplos (variaran porque las genera el LLM):\n",
    "-  El contacto fue anadido con exito\n",
    "-  Se anadio el contacto\n",
    "-  El email de juan perez es juanperez@mail.com\n",
    "\n",
    "Link de ayuda: https://github.com/cohere-ai/notebooks/blob/main/notebooks/agents/Vanilla_Tool_Use_v2.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e43cb9-5e6a-4807-9818-c85408f1ba58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_contact(name, phone, email):\n",
    "    \"\"\"\n",
    "    Agrega un contacto al diccionario.\n",
    "    Parámetros:\n",
    "        name (str): Nombre del contacto.\n",
    "        phone (str): Número de teléfono del contacto.\n",
    "        email (str): Correo electrónico del contacto.\n",
    "    Retorna:\n",
    "        str: Mensaje confirmando la adición del contacto.\n",
    "    \"\"\"\n",
    "    contacts[name] = {'phone': phone, 'email': email}\n",
    "    return \"Contacto añadido con éxito.\"\n",
    "\n",
    "def get_information(name):\n",
    "    \"\"\"\n",
    "    Recupera la información de un contacto.\n",
    "    Parámetros:\n",
    "        name (str): Nombre del contacto.\n",
    "    Retorna:\n",
    "        dict/str: Información del contacto o un mensaje si no existe.\n",
    "    \"\"\"\n",
    "    if name in contacts:\n",
    "        return contacts[name]\n",
    "    else:\n",
    "        return \"Contacto no encontrado.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0fb79ea5-4ae3-4367-8213-8c38059b3f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "contacts = {\n",
    "                        'Joaquin Lopez':{'tel': 15456663258, 'mail': 'Joacolocolopez@gmail.com'},\n",
    "                      'Flavio Oncativo':{'tel': 1545554178, 'mail': 'FOncativo@hotmail.com'}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7d3bed9a-d5d1-49c3-b91b-8cd23bb9c9ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Consulta: Agrega a Juan Pérez con el número 555-1234 y el correo juanperez@mail.com.\n",
      "Respuesta: Contacto añadido con éxito.\n",
      "--------------------------------------------------\n",
      "Consulta: Guarda a Lucía Gómez con el número 555-5678 y el correo luciagomez@gmail.com.\n",
      "Respuesta: Contacto añadido con éxito.\n",
      "--------------------------------------------------\n",
      "Consulta: Cual es el email de Juan Pérez?\n",
      "Respuesta: El email de Juan Pérez es juanperez@mail.com.\n",
      "--------------------------------------------------\n",
      "Consulta: Agrega a Trinidad Castro con el numero 456-2243 y el correo trini@gmail.com\n",
      "Respuesta: Contacto añadido con éxito.\n",
      "--------------------------------------------------\n",
      "Consulta: Cuál es el numero de telefono de Trinidad Castro?\n",
      "Respuesta: El número de teléfono de Trinidad Castro es 456-2243\n",
      "--------------------------------------------------\n",
      "Consulta: Cual es el email de Lucía Gómez? \n",
      "Respuesta: El email de Lucía Gómez es luciagomez@gmail.com.\n",
      "--------------------------------------------------\n",
      "Consulta: Agrega a Sebastian Castro con el numero 428-7277 y el correo pi_Sebastian@gmail.com\n",
      "Respuesta: Contacto añadido con éxito.\n",
      "--------------------------------------------------\n",
      "Consulta: Cuál es el numero de telefono de Sebastian Castro?\n",
      "Respuesta: El número de teléfono de Sebastian Castro es 428-7277\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import cohere\n",
    "import re\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Cargar las variables de entorno desde el archivo .env\n",
    "load_dotenv()\n",
    "\n",
    "# Obtener la clave de API desde la variable de entorno\n",
    "api_key = os.getenv(\"COHERE_API_KEY\")\n",
    "\n",
    "# Inicializa el cliente de Cohere usando la clave de API desde la variable de entorno\n",
    "co = cohere.ClientV2(api_key)\n",
    "\n",
    "\n",
    "\n",
    "# Diccionario de contactos\n",
    "contacts = {\n",
    "    'Joaquin Lopez': {'phone': '15456663258', 'email': 'Joacolocolopez@gmail.com'},\n",
    "    'Flavio Oncativo': {'phone': '1545554178', 'email': 'FOncativo@hotmail.com'}\n",
    "}\n",
    "\n",
    "# Función para agregar contacto\n",
    "def add_contact(name, phone, email):\n",
    "    \"\"\"\n",
    "    Agrega un contacto al diccionario.\n",
    "    Parámetros:\n",
    "        name (str): Nombre del contacto.\n",
    "        phone (str): Número de teléfono del contacto.\n",
    "        email (str): Correo electrónico del contacto.\n",
    "    Retorna:\n",
    "        str: Mensaje confirmando la adición del contacto.\n",
    "    \"\"\"\n",
    "    contacts[name] = {'phone': phone, 'email': email}\n",
    "    return \"Contacto añadido con éxito.\"\n",
    "\n",
    "# Función para obtener información del contacto\n",
    "def get_information(name):\n",
    "    \"\"\"\n",
    "    Recupera la información de un contacto.\n",
    "    Parámetros:\n",
    "        name (str): Nombre del contacto.\n",
    "    Retorna:\n",
    "        dict/str: Información del contacto o un mensaje si no existe.\n",
    "    \"\"\"\n",
    "    if name in contacts:\n",
    "        return contacts[name]\n",
    "    else:\n",
    "        return \"Contacto no encontrado.\"\n",
    "\n",
    "# Función para procesar la consulta utilizando LLM\n",
    "\n",
    "def process_query(user_query):\n",
    "    user_query = user_query.lower()\n",
    "\n",
    "    # Caso 1: Agregar contacto\n",
    "    pattern_add_contact = (\n",
    "        r'(?:agrega|guarda) a ([a-záéíóúñ\\s]+?)'  # Captura el nombre del contacto\n",
    "        r'(?:\\s*(?:con el (?:número|numero)|su teléfono es|numero es)\\s*([\\d\\-]+))?'  # Captura el teléfono (opcional)\n",
    "        r'(?:\\s*(?:y el (?:correo|email)|y su (?:correo|email) es|email es)\\s*([\\w\\.-]+@[\\w\\.-]+))'  # Captura el correo\n",
    "    )\n",
    "    \n",
    "    if match := re.search(pattern_add_contact, user_query, re.IGNORECASE):\n",
    "        name, phone, email = match.groups()\n",
    "        phone = phone or \"No especificado\"\n",
    "        return add_contact(name.title().strip(), phone.strip(), email.strip())\n",
    "\n",
    "    # Caso 2: Obtener email de un contacto\n",
    "    pattern_get_email = r'(?:c[uú]al es el email de|correo de) ([a-záéíóúñ\\s]+)\\?'\n",
    "    if match := re.search(pattern_get_email, user_query, re.IGNORECASE):\n",
    "        name = match.group(1).title().strip()\n",
    "        contact_info = get_information(name)\n",
    "        if contact_info != \"Contacto no encontrado.\":\n",
    "            return f\"El email de {name} es {contact_info['email']}\"\n",
    "        else:\n",
    "            return f\"No se encontró el contacto {name}.\"\n",
    "\n",
    "    # Caso 3: Obtener teléfono de un contacto\n",
    "    pattern_get_phone = r'(?:c[uú]al es el n[uú]mero de tel[eé]fono de|tel[eé]fono de) ([a-záéíóúñ\\s]+)\\?'\n",
    "    if match := re.search(pattern_get_phone, user_query, re.IGNORECASE):\n",
    "        name = match.group(1).title().strip()\n",
    "        contact_info = get_information(name)\n",
    "        if contact_info != \"Contacto no encontrado.\":\n",
    "            return f\"El número de teléfono de {name} es {contact_info['phone']}\"\n",
    "        else:\n",
    "            return f\"No se encontró el contacto {name}.\"\n",
    "\n",
    "    # Caso 4: Obtener nombre por email\n",
    "    pattern_get_name_by_email = r'email ([\\w\\.-]+@[\\w\\.-]+)\\?'\n",
    "    if match := re.search(pattern_get_name_by_email, user_query, re.IGNORECASE):\n",
    "        email = match.group(1).strip().lower()\n",
    "        contact_name = next((name for name, info in contacts.items() if info['email'].lower() == email), None)\n",
    "        if contact_name:\n",
    "            return f\"El nombre del contacto con email {email} es {contact_name}\"\n",
    "        else:\n",
    "            return f\"No se encontró el contacto con email {email}.\"\n",
    "\n",
    "    # Consulta no entendida\n",
    "    return \"No se pudo procesar la consulta.\"\n",
    "\n",
    "\n",
    "\n",
    "# Consultas de ejemplo\n",
    "queries = [\n",
    "    \"Agrega a Juan Pérez con el número 555-1234 y el correo juanperez@mail.com.\",\n",
    "    \"Guarda a Lucía Gómez con el número 555-5678 y el correo luciagomez@gmail.com.\",\n",
    "    \"Cual es el email de Juan Pérez?\",\n",
    "    \"Agrega a Trinidad Castro con el numero 456-2243 y el correo trini@gmail.com\",\n",
    "    \"Cuál es el numero de telefono de Trinidad Castro?\",\n",
    "    \"Cual es el email de Lucía Gómez? \",\n",
    "    \"Agrega a Sebastian Castro con el numero 428-7277 y el correo pi_Sebastian@gmail.com\",\n",
    "    \"Cuál es el numero de telefono de Sebastian Castro?\"\n",
    "]\n",
    "\n",
    "# Procesar las consultas y asegurar que los contactos se actualicen adecuadamente\n",
    "for query in queries:\n",
    "    print(f\"Consulta: {query}\")\n",
    "    respuesta = process_query(query)\n",
    "    print(f\"Respuesta: {respuesta}\")\n",
    "    print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ddaf4d1-6ab9-4707-823d-11ada125b0f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c36ef67d-dd54-41e7-bef5-f89ee575603f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TIPS\n",
    "# Probar primero generando una funcion y llamarla, luego anadir la otra\n",
    "# Plantearlo paso por paso en distintas celdas, analizar las salidas y las entradas, como identificamos a que funcion llamar?\n",
    "# luego automatizar dentro de una sola celda\n",
    "\n",
    "\n",
    "# Lo importante es entregar hasta donde lleguen, sea una funcion, las dos pero sin poder hacer el flujo automatico, lo que puedan, siempre y cuando este\n",
    "# claro lo que se quizo hacer con comentarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ace85d2-cd00-4bd4-81e2-68113eb9f8d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e9d8badf-dc90-4005-b916-8e528105d797",
   "metadata": {},
   "source": [
    "## Ejercicio 3\n",
    "\n",
    "Crear una funcion llamada \"history_answer\", que toma como parametro de entrada una pregunta sobre un contexto dado y la salida es la respuesta final del proceso impulsado por un LLM.\n",
    "\n",
    "Dada una historia, el usuario podra hacer preguntas sobre la misma y el LLM debe responder siguiendo los siguientes lineamientos:\n",
    "\n",
    "REQUISITOS DE LA RESPUESTA\n",
    "- las respuestas deben ser en base a la historia\n",
    "- ante la misma pregunta siempre debe responder de la misma manera.\n",
    "- que responda en solo una oracion.\n",
    "- el idioma que responde debe ser el mismo que con el que se pregunta (ingles, espanol, portugues).\n",
    "- que agregue emojis en la oracion que resuman el contenido de la misma.\n",
    "- que responda siempre en tercera persona.\n",
    "- si la pregunta no tiene relacion alguna con el contexto, la respuesta debe ser 'Lo siento no puedo ayudarte con eso'.\n",
    "- Responder con 'Hakuna Matata!' al final de **todas** las respuestas (no importa idioma ni cantidad de tokens).\n",
    "\n",
    "**Ayudin**: \n",
    "- No se limiten a usar 1 solo request al LLM, pueden dividirlo en partes para que por un lado se verifique el idioma, por otro lado se verifique si la pregunta tiene relacion con el contexto, etc\n",
    "\n",
    "- Estructuren bien el prompt procurando separar instrucciones, contexto(historia) y pregunta del usuario.\n",
    "\n",
    "- Recuerden usar el system message y user message.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f36820-b7d3-4813-a0c3-351c598106ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ejemplo flojo de estructura de prompt\n",
    "# prompt = f\"Responde a la pregunta: {pregunta} de manera concisa y divertida en base a la siguiente historia: {historia}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5602f56-4032-4cc6-a2c5-7b29cf2a2a5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa65537-3aa6-43c6-87e9-86a689f8e1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def history_answer(pregunta):\n",
    "    # your code here\n",
    "\n",
    "    return respuesta_al_usuario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3aaa967-d87f-45d9-9a72-6fc63afc931c",
   "metadata": {},
   "outputs": [],
   "source": [
    "historia = \"\"\"En un pequeño feudo medieval, Thomas, un joven campesino de dieciséis años, trabajaba desde el amanecer en los campos de trigo del señor feudal. El sol apenas había salido cuando él ya había arado más de lo que sus manos podían soportar. La vida era dura, pero su familia dependía de la cosecha para pagar los impuestos y mantener su hogar de madera y paja.\n",
    "\n",
    "Un día, el feudo fue sacudido por noticias de guerra. El rey había llamado a todos los hombres en edad de luchar. Thomas sabía que, al igual que otros jóvenes, no tenía elección. Cambió la hoz por una lanza rudimentaria y se unió a la milicia local. Sin entrenamiento, fue empujado a un campo de batalla embarrado, donde el acero resonaba y los gritos de los hombres llenaban el aire.\n",
    "\n",
    "La batalla fue un caos. Thomas, con el corazón latiendo en su pecho como un tambor de guerra, apenas podía distinguir amigo de enemigo. Logró esquivar una espada, pero cayó al suelo, cubierto de lodo y sangre. Levantándose, vio cómo un compañero caía junto a él, sus ojos abiertos, vacíos.\n",
    "\n",
    "Cuando la batalla terminó, el silencio era tan profundo como el vacío que sentía. Thomas regresó al feudo, diferente, marcado por la muerte y la violencia. Su madre lo recibió con lágrimas en los ojos, pero él, con la mirada fija en el horizonte, sabía que la inocencia había quedado atrás, enterrada en aquel campo de batalla. La paz del feudo ya no era la misma; él tampoco.\"\"\"\n",
    "\n",
    "\n",
    "pregunta = # insertar pregunta relacionada  o  no\n",
    "\n",
    "\n",
    "# respuesta\n",
    "print(history_answer(pregunta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "31f246d9-ec91-498a-a06a-172947316325",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La pregunta es: \"¿Cuál es el nombre del héroe?\" 🏰🗡️⚔️, Hakuna Matata!\n",
      "Thomas worked tirelessly in the feudal fields, ploughing and harvesting wheat 🌾., Hakuna Matata!\n",
      "La pregunta es: \"¿Cuál es el nombre del héroe?\" 🏰🗡️⚔️, Hakuna Matata!\n",
      "Thomas tem dezesseis anos de idade, e sua vida mudou para sempre quando foi forçado a lutar em uma guerra 😞., Hakuna Matata!\n",
      "Lo siento no puedo ayudarte con eso, Hakuna Matata!\n"
     ]
    }
   ],
   "source": [
    "import cohere\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from hashlib import md5\n",
    "\n",
    "# Cargar las variables de entorno desde el archivo .env\n",
    "load_dotenv()\n",
    "\n",
    "# Obtener la clave de API desde la variable de entorno\n",
    "api_key = os.getenv(\"COHERE_API_KEY\")\n",
    "\n",
    "# Inicializa el cliente de Cohere usando la clave de API desde la variable de entorno\n",
    "co = cohere.ClientV2(api_key)\n",
    "\n",
    "historia = \"\"\"En un pequeño feudo medieval, Thomas, un joven campesino de dieciséis años, trabajaba desde el amanecer en los campos de trigo del señor feudal. El sol apenas había salido cuando él ya había arado más de lo que sus manos podían soportar. La vida era dura, pero su familia dependía de la cosecha para pagar los impuestos y mantener su hogar de madera y paja.\n",
    "\n",
    "Un día, el feudo fue sacudido por noticias de guerra. El rey había llamado a todos los hombres en edad de luchar. Thomas sabía que, al igual que otros jóvenes, no tenía elección. Cambió la hoz por una lanza rudimentaria y se unió a la milicia local. Sin entrenamiento, fue empujado a un campo de batalla embarrado, donde el acero resonaba y los gritos de los hombres llenaban el aire.\n",
    "\n",
    "La batalla fue un caos. Thomas, con el corazón latiendo en su pecho como un tambor de guerra, apenas podía distinguir amigo de enemigo. Logró esquivar una espada, pero cayó al suelo, cubierto de lodo y sangre. Levantándose, vio cómo un compañero caía junto a él, sus ojos abiertos, vacíos.\n",
    "\n",
    "Cuando la batalla terminó, el silencio era tan profundo como el vacío que sentía. Thomas regresó al feudo, diferente, marcado por la muerte y la violencia. Su madre lo recibió con lágrimas en los ojos, pero él, con la mirada fija en el horizonte, sabía que la inocencia había quedado atrás, enterrada en aquel campo de batalla. La paz del feudo ya no era la misma; él tampoco.\"\"\"\n",
    "\n",
    "# Diccionario para almacenar preguntas y respuestas\n",
    "respuestas_cache = {}\n",
    "\n",
    "def history_answer(pregunta):\n",
    "    # Hash de la pregunta para consistencia en las respuestas\n",
    "    pregunta_hash = md5(pregunta.encode()).hexdigest()\n",
    "\n",
    "    # Verificar si la respuesta está en la caché\n",
    "    if pregunta_hash in respuestas_cache:\n",
    "        return respuestas_cache[pregunta_hash]\n",
    "\n",
    "    # Detectar el idioma de la pregunta\n",
    "    prompt_idioma = f\"SYSTEM: Eres un experto en detección de idiomas.\\nUSER: Detecta el idioma de la siguiente pregunta: {pregunta}\"\n",
    "    idioma_response = co.generate(\n",
    "        model='command-r-plus',\n",
    "        prompt=prompt_idioma,\n",
    "        max_tokens=10\n",
    "    )\n",
    "    idioma = idioma_response.generations[0].text.strip().lower()\n",
    "\n",
    "    # Verificar si la pregunta está relacionada con la historia\n",
    "    prompt_related = f\"SYSTEM: Eres un experto en análisis de textos.\\nUSER: ¿La siguiente pregunta está relacionada con la historia dada? Historia: {historia}\\nPregunta: {pregunta}\"\n",
    "    related_response = co.generate(\n",
    "        model='command-r-plus',\n",
    "        prompt=prompt_related,\n",
    "        max_tokens=10\n",
    "    )\n",
    "    related = related_response.generations[0].text.strip().lower()\n",
    "\n",
    "    if \"yes\" in related or \"sí\" in related or \"sim\" in related:\n",
    "        # Generar respuesta basada en la historia\n",
    "        prompt_respuesta = f\"SYSTEM: Eres un experto en responder preguntas basadas en contextos.\\nUSER: Responde en una oración en {idioma} a la siguiente pregunta: {pregunta}, en base a la historia: {historia}. Incluye emojis en la respuesta que resuman el contenido y responde siempre en tercera persona.\"\n",
    "        respuesta_response = co.generate(\n",
    "            model='command-r-plus',\n",
    "            prompt=prompt_respuesta,\n",
    "            max_tokens=60\n",
    "        )\n",
    "        respuesta = respuesta_response.generations[0].text.strip()\n",
    "    else:\n",
    "        respuesta = \"Lo siento no puedo ayudarte con eso\"\n",
    "\n",
    "    # Añadir \"Hakuna Matata!\" al final de la respuesta\n",
    "    respuesta_final = f\"{respuesta}, Hakuna Matata!\"\n",
    "\n",
    "    # Almacenar la respuesta en la caché\n",
    "    respuestas_cache[pregunta_hash] = respuesta_final\n",
    "\n",
    "    return respuesta_final\n",
    "\n",
    "# Ejemplo de uso\n",
    "pregunta = \"¿Cómo se llama el protagonista?\"\n",
    "print(history_answer(pregunta))\n",
    "\n",
    "pregunta = \"What did Thomas work on in the fields?\"\n",
    "print(history_answer(pregunta))\n",
    "\n",
    "pregunta = \"¿Cómo se llama el protagonista?\"\n",
    "print(history_answer(pregunta))\n",
    "\n",
    "pregunta = \"Quantos anos tem Thomas?\"\n",
    "print(history_answer(pregunta))\n",
    "\n",
    "pregunta = \"¿Cuál es la capital de Francia?\"\n",
    "print(history_answer(pregunta))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "795f451e-6c12-4631-895f-fa6ac8f16b74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "db6e9a7d-aa39-4a01-ba55-9a7f4ea39522",
   "metadata": {},
   "source": [
    "## Ejercicio 4\n",
    "\n",
    "Crear un chatbot sencillo impulsado por un LLM. \n",
    "\n",
    "Dicho bot esta destinado a un usuario final y debe cumplir las siguientes **condiciones en sus respuestas**:\n",
    "\n",
    "- Responder en no mas de 70 tokens.\n",
    "- Responder de manera positiva, con un tono entusiasta.\n",
    "- Responder con consejos útiles, como si fueras un tutor.\n",
    "\n",
    " \n",
    "**Otras consideraciones**:\n",
    "\n",
    "Respetar el formato de la interfaz provista por el ejercicio.\n",
    "\n",
    "Ademas agregar al codigo propuesto un historial de conversaciones para que el bot pueda mantener el hilo de lo que se esta hablando. Para probar no usen mas de 3 conversaciones anidadas para no enviarle tantos tokens.\n",
    "\n",
    "Dejar impreso en el notebook el historial de la conversacion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5284210f-23a3-4db1-b315-db724a3bb3a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa475fa8-e48b-423e-9006-7478a462129c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1085d9dec2fc4a0a97116e9294b8eef6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', placeholder='Escribe tu mensaje aquí...')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1c63cd64d904a509d86e947708efa36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Enviar', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29c81afa15284e069d492bda7de8d846",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Crear widgets de entrada y salida\n",
    "input_box = widgets.Text(placeholder='Escribe tu mensaje aquí...')\n",
    "send_button = widgets.Button(description='Enviar')\n",
    "output_box = widgets.Output()\n",
    "\n",
    "# chat_history = []\n",
    "\n",
    "# Función de respuesta simulada del chatbot\n",
    "def chatbot_response(message):\n",
    "    # Aquí puedes conectar tu modelo o lógica de chatbot real\n",
    "    responses = {\n",
    "        \"hola\": \"¡Hola! ¿En qué puedo ayudarte?\",\n",
    "        \"adiós\": \"¡Hasta luego!\",\n",
    "    }\n",
    "\n",
    "    return responses.get(message.lower(), \"Lo siento, no entiendo esa pregunta.\")\n",
    "\n",
    "# Función de manejo del botón\n",
    "def on_send_button_clicked(b):\n",
    "    with output_box:\n",
    "        clear_output(wait=True)\n",
    "        user_message = input_box.value\n",
    "        if user_message.strip():\n",
    "            print(f\"Tú: {user_message}\")\n",
    "            response = chatbot_response(user_message)\n",
    "            print(f\"Chatbot: {response}\")\n",
    "        input_box.value = ''\n",
    "\n",
    "# Asociar función al botón\n",
    "send_button.on_click(on_send_button_clicked)\n",
    "\n",
    "# Mostrar widgets\n",
    "display(input_box, send_button, output_box)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "436d5bce-0189-4ecd-a06d-fcc7a81315b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "726e62dbd1b64735876a4e82f96428bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', placeholder='Escribe tu mensaje aquí...')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b27fe53db4f144cba57fdaf9d41860bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Enviar', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9668eabdd6414b0996a81d292277e5c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import cohere\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Cargar las variables de entorno desde el archivo .env\n",
    "load_dotenv()\n",
    "\n",
    "# Obtener la clave de API desde la variable de entorno\n",
    "api_key = os.getenv(\"COHERE_API_KEY\")\n",
    "\n",
    "# Inicializa el cliente de Cohere usando la clave de API desde la variable de entorno\n",
    "co = cohere.ClientV2(api_key)\n",
    "\n",
    "# Crear widgets de entrada y salida\n",
    "input_box = widgets.Text(placeholder='Escribe tu mensaje aquí...')\n",
    "send_button = widgets.Button(description='Enviar')\n",
    "output_box = widgets.Output()\n",
    "\n",
    "# Historial de conversaciones\n",
    "chat_history = []\n",
    "\n",
    "# Función de respuesta del chatbot\n",
    "def chatbot_response(message):\n",
    "    prompt = f\"Conversa con el usuario siguiendo estas reglas: Responde en no más de 70 tokens. Responde de manera positiva y entusiasta. Da consejos útiles como si fueras un tutor. Mantén el historial de la conversación.\\nHistorial de la conversación:\\n{''.join(chat_history)}\\nUsuario: {message}\\nChatbot:\"\n",
    "\n",
    "    response = co.generate(\n",
    "        model='command',\n",
    "        prompt=prompt,\n",
    "        max_tokens=70\n",
    "    )\n",
    "\n",
    "    return response.generations[0].text.strip()\n",
    "\n",
    "# Función de manejo del botón\n",
    "def on_send_button_clicked(b):\n",
    "    with output_box:\n",
    "        clear_output(wait=True)\n",
    "        user_message = input_box.value\n",
    "        if user_message.strip():\n",
    "            print(f\"Tú: {user_message}\")\n",
    "            chat_history.append(f\"Usuario: {user_message}\\n\")\n",
    "            response = chatbot_response(user_message)\n",
    "            chat_history.append(f\"Chatbot: {response}\\n\")\n",
    "            print(f\"Chatbot: {response}\")\n",
    "            # Mostrar el historial de conversaciones\n",
    "            print(\"\\nHistorial de conversación:\")\n",
    "            for entry in chat_history:\n",
    "                print(entry)\n",
    "        input_box.value = ''\n",
    "\n",
    "# Asociar función al botón\n",
    "send_button.on_click(on_send_button_clicked)\n",
    "\n",
    "# Mostrar widgets\n",
    "display(input_box, send_button, output_box)\n",
    "\n",
    "# Imprimir historial de la conversación\n",
    "for entry in chat_history:\n",
    "    print(entry)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a213283-3ef7-4df8-8b7f-3bb11d58362d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(conversation_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6fb6d6a-1c32-42e5-a1ee-d62b2bc0785a",
   "metadata": {},
   "source": [
    "### RECOMENDACIONES GENERALES\n",
    "\n",
    "No se confien probando con un par de respuestas y ya, hagan minimo 5 pruebas por ejercicio para asi tener mas chances de visualizar errores en la generacion del contenido.\n",
    "\n",
    "Prueben combinar LLMs con programacion convencional para los casos que vean convenientes (decisiones if else, respuestas estaticas, etc)\n",
    "\n",
    "Prueben con distintos modelos de Cohere, hay algunos optimizados para ciertas aplicaciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a3f2e37-bf32-43b7-8958-e39954a20fb1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
